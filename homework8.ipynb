{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e9580ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e9b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape = (150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f1f2ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 150, 150, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aff8d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_lay = keras.layers.Conv2D(\n",
    "    filters=32,\n",
    "    kernel_size = (3,3),\n",
    "    activation='relu'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26867dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = conv_lay(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ce742e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 148, 148, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42c96f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooling = keras.layers.MaxPooling2D(\n",
    "    pool_size=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "513f7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pooling(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80e44acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 74, 74, 32])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91cd1a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = keras.layers.Flatten()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08e58d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 175232])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "476f9398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'flatten/Identity:0' shape=(None, 175232) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a47c308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner = keras.layers.Dense(64,activation='relu')(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4e505fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense/Identity:0' shape=(None, 64) dtype=float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11b49ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = keras.layers.Dense(1,activation='sigmoid')(inner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6be9800a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1/Identity:0' shape=(None, 1) dtype=float32>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01e6cc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bd025eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "  model = keras.Model(inputs,outputs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34185eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr=0.002,momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7a404e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 175232)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                11214912  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83c6987f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84ddd853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_gen.flow_from_directory(\n",
    "    './train',\n",
    "    target_size=(150,150),\n",
    "    class_mode='binary',\n",
    "    batch_size = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb4d9227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_ds = train_gen.flow_from_directory(\n",
    "    './validation',\n",
    "    target_size=(150,150),\n",
    "    class_mode='binary',\n",
    "    batch_size = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25a384b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3c3ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "model.compile(optimizer=optimizer,loss=loss,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27a528d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-11-21 19:48:00.894 ip-172-16-32-147:9335 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2021-11-21 19:48:00.928 ip-172-16-32-147:9335 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 0.6943 - accuracy: 0.5160 - val_loss: 0.6889 - val_accuracy: 0.5120\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.6887 - accuracy: 0.5400 - val_loss: 0.6823 - val_accuracy: 0.5610\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 0.6831 - accuracy: 0.5585 - val_loss: 0.6762 - val_accuracy: 0.5910\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.6812 - accuracy: 0.5685 - val_loss: 0.6689 - val_accuracy: 0.5920\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.6760 - accuracy: 0.5735 - val_loss: 0.6633 - val_accuracy: 0.6100\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.6752 - accuracy: 0.5855 - val_loss: 0.6561 - val_accuracy: 0.6250\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.6719 - accuracy: 0.5740 - val_loss: 0.6564 - val_accuracy: 0.6280\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.6653 - accuracy: 0.5830 - val_loss: 0.6506 - val_accuracy: 0.6260\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.6624 - accuracy: 0.5965 - val_loss: 0.6470 - val_accuracy: 0.6290\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.6542 - accuracy: 0.6145 - val_loss: 0.6476 - val_accuracy: 0.6260\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,steps_per_epoch=100,epochs=10,validation_data=val_ds,validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6e5ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history.history['accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "97a33930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57375"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(np.array(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "738b3377",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1618d0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011661345598921949"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_loss).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85b44984",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc08e46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_gen.flow_from_directory(\n",
    "    './train',\n",
    "    target_size=(150,150),\n",
    "    class_mode='binary',\n",
    "    batch_size = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "98c1f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae455058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_ds = val_gen.flow_from_directory(\n",
    "    './validation',\n",
    "    target_size=(150,150),\n",
    "    class_mode='binary',\n",
    "    batch_size = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97f45431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate for 50 steps\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 18s 177ms/step - loss: 0.6758 - accuracy: 0.5770 - val_loss: 0.6495 - val_accuracy: 0.6360\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.6750 - accuracy: 0.5750 - val_loss: 0.6528 - val_accuracy: 0.6270\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 18s 178ms/step - loss: 0.6688 - accuracy: 0.5890 - val_loss: 0.6469 - val_accuracy: 0.6300\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 18s 181ms/step - loss: 0.6664 - accuracy: 0.5955 - val_loss: 0.6623 - val_accuracy: 0.5920\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.6713 - accuracy: 0.5865 - val_loss: 0.6489 - val_accuracy: 0.6370\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 0.6709 - accuracy: 0.5795 - val_loss: 0.6474 - val_accuracy: 0.6270\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.6574 - accuracy: 0.6050 - val_loss: 0.6441 - val_accuracy: 0.6190\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.6698 - accuracy: 0.5795 - val_loss: 0.6605 - val_accuracy: 0.5910\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 18s 179ms/step - loss: 0.6612 - accuracy: 0.5985 - val_loss: 0.6408 - val_accuracy: 0.6280\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 18s 178ms/step - loss: 0.6563 - accuracy: 0.6010 - val_loss: 0.6393 - val_accuracy: 0.6460\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,steps_per_epoch=100,epochs=10,validation_data=val_ds,validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8970cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7b6690c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6492560049295426"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(val_loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75f232a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40cb3454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.636, 0.627, 0.63, 0.592, 0.637, 0.627, 0.619, 0.591, 0.628, 0.646]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c4bc499",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc510 = val_acc[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fe9c2e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6246667"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(val_acc510).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da54f1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6246667"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.average(np.array(val_acc510))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
